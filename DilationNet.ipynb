{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from pathlib import Path\n",
    "from math import floor, ceil\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from rasterio import windows as rio_windows\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import Activation, add, multiply\n",
    "from keras.layers import MaxPooling2D, SpatialDropout2D\n",
    "from keras.layers import UpSampling2D, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Concatenate, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as kb\n",
    "from keras.backend import int_shape\n",
    "\n",
    "def tversky_index(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        alpha: float = 0.5,\n",
    "        beta: float = 0.5,\n",
    "        eps: float = 1e-10,\n",
    "        preserve_axis=(0, -1)\n",
    "):\n",
    "    \"\"\"\n",
    "    Ref A: https://arxiv.org/abs/1706.05721\n",
    "    alpha = beta = 0.5 : Dice coefficient\n",
    "    alpha = beta = 1   : Tanimoto coefficient (also known as Jaccard Index)\n",
    "    alpha + beta = 1   : Produces set of F*-scores\n",
    "\n",
    "    Ref B: https://arxiv.org/abs/1707.03237\n",
    "    The scores should be computed for each voxel in a batch and for each\n",
    "    class separately. Thus for a 4D tensor the resultant scores should be a\n",
    "    2D tensor having the batch axis and label axis. Therefore for a typical\n",
    "    channels last 4D tensor the axis 0 and axis -1 should be preserved (See\n",
    "    default value for `preserve_axis` parameter)\n",
    "\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :param alpha:\n",
    "    :param beta:\n",
    "    :param eps:\n",
    "    :param preserve_axis:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # assert int_shape(y_true) == int_shape(y_pred), \"Shape Mismatch\"\n",
    "\n",
    "    once = kb.ones(kb.shape(y_true))\n",
    "    p0 = y_pred  # probability that voxels are class i\n",
    "    p1 = once - y_pred  # probability that voxels are not class i\n",
    "    g0 = y_true\n",
    "    g1 = once - y_true\n",
    "\n",
    "    dims = list(range(kb.ndim(p0)))\n",
    "    if isinstance(preserve_axis, int):\n",
    "        preserve_axis = (preserve_axis,)\n",
    "    assert isinstance(\n",
    "        preserve_axis, (tuple, list)\n",
    "    ) and all(\n",
    "        [\n",
    "            (isinstance(n, int) and ((0 <= n < kb.ndim(p0)) or (-kb.ndim(p0) <= n < 0)))\n",
    "            for n in preserve_axis\n",
    "         ]\n",
    "    ), '`preserve_axis`: Illegal value!'\n",
    "    preserve_axis = list(set(preserve_axis))\n",
    "    for ax in preserve_axis:\n",
    "        del dims[ax]\n",
    "\n",
    "    numerator = kb.sum(\n",
    "        x=p0 * g0,\n",
    "        axis=dims\n",
    "    ) + eps\n",
    "    denominator = numerator + alpha * kb.sum(\n",
    "        x=p0 * g1,\n",
    "        axis=dims\n",
    "    ) + beta * kb.sum(\n",
    "        x=p1 * g0,\n",
    "        axis=dims\n",
    "    ) + eps\n",
    "\n",
    "    t = numerator / denominator\n",
    "    return t\n",
    "\n",
    "def tversky_loss(\n",
    "        alpha: float = 0.5,\n",
    "        beta: float = 0.5,\n",
    "        eps: float = 1e-10,\n",
    "        along_axis=(0, -1),\n",
    "        norm=True\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    :param alpha:\n",
    "    :param beta:\n",
    "    :param eps:\n",
    "    :param along_axis:\n",
    "    :param norm\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def tversky_loss_function(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "    ):\n",
    "        t_values = tversky_index(\n",
    "            y_true=y_true,\n",
    "            y_pred=y_pred,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            eps=eps,\n",
    "            preserve_axis=along_axis\n",
    "        )\n",
    "        losses = kb.ones_like(x=t_values, dtype=t_values.dtype) - t_values\n",
    "        if norm:\n",
    "            return kb.mean(x=loses, axis=None, keepdims=False)\n",
    "        else:\n",
    "            agg_loss = kb.sum(x=losses, axis=None, keepdims=False)\n",
    "            return agg_loss\n",
    "    return tversky_loss_function\n",
    "\n",
    "def focal_tversky_loss(\n",
    "    alpha: float = 0.5,\n",
    "    beta: float = 0.5,\n",
    "    gamma=0.75,\n",
    "    eps: float = 1e-10,\n",
    "    along_axis=(0, -1),\n",
    "    norm=True\n",
    "):\n",
    "    def focal_tversky_loss_function(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "    ):\n",
    "        t_values = tversky_index(\n",
    "            y_true=y_true,\n",
    "            y_pred=y_pred,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            eps=eps,\n",
    "            preserve_axis=along_axis\n",
    "        )\n",
    "        losses = kb.pow((kb.ones_like(x=t_values, dtype=t_values.dtype) - t_values), gamma)\n",
    "        if norm:\n",
    "            return kb.mean(x=losses, axis=None, keepdims=False)\n",
    "        else:\n",
    "            agg_loss = kb.sum(x=losses, axis=None, keepdims=False)\n",
    "            return agg_loss\n",
    "    return focal_tversky_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "droprate = 0.3\n",
    "image_height = 6000\n",
    "image_width = 6000\n",
    "window_height = 512\n",
    "window_width = 512\n",
    "min_height_overlap = 32\n",
    "min_width_overlap = 32\n",
    "boundless_flag = True\n",
    "class_count = 6\n",
    "data_shuffle = True\n",
    "batchsize=1\n",
    "bands = (1, 2, 3, 4, 5)\n",
    "image_features = len(bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_augs = (\n",
    "    # ((lambda m : m), True),\n",
    "    (partial(np.rot90, k=1, axes=(1, 2)), True),\n",
    "    (partial(np.rot90, k=2, axes=(1, 2)), True),\n",
    "    (partial(np.rot90, k=3, axes=(1, 2)), True),\n",
    "    (partial(np.flip, axis=1), True),\n",
    "    (partial(np.flip, axis=2), True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data\n",
    "config_dir = Path('Configs')\n",
    "train_config = config_dir / 'Train_Map.json'\n",
    "valid_config = config_dir / 'Validation_Map.json'\n",
    "test_config = config_dir / 'Test_Map.json'\n",
    "model_dir = Path(\"Models\")\n",
    "mplot = model_dir / \"Model_Plot.png\"\n",
    "model_max_accuracy = model_dir / 'Model_MaxAccuracy.h5' \n",
    "model_min_loss = model_dir / 'Model_MinLoss.h5'\n",
    "log_d = Path('Logs')\n",
    "\n",
    "with open(train_config.as_posix(), 'r') as tm:\n",
    "    train_map = json.load(tm)\n",
    "\n",
    "with open(valid_config.as_posix(), 'r') as tm:\n",
    "    valid_map = json.load(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows(img_height, img_width, win_height, win_width, min_hoverlap, min_woverlap, boundless=False):\n",
    "    hc = ceil((img_height - min_hoverlap) / (win_height - min_hoverlap))\n",
    "    wc = ceil((img_width - min_woverlap) / (win_width - min_woverlap))\n",
    "    \n",
    "    \n",
    "    h_overlap = ((hc * win_height) - img_height) // (hc - 1)\n",
    "    w_overlap = ((wc * win_height) - img_width) // (wc - 1)\n",
    "    \n",
    "    \n",
    "    hslack_res = ((hc * win_height) - img_height) % (hc - 1)\n",
    "    wslack_res = ((wc * win_width) - img_width) % (wc - 1)\n",
    "    \n",
    "    dh = win_height - h_overlap\n",
    "    dw = win_width - w_overlap\n",
    "    \n",
    "    row_offsets = np.arange(0, (img_height-h_overlap), dh)\n",
    "    col_offsets = np.arange(0, (img_width-w_overlap), dw)\n",
    "    \n",
    "    if hslack_res > 0:\n",
    "        row_offsets[-hslack_res:] -= np.arange(1, (hslack_res + 1), 1)\n",
    "    if wslack_res > 0:\n",
    "        col_offsets[-wslack_res:] -= np.arange(1, (wslack_res + 1), 1)\n",
    "    \n",
    "    row_offsets = row_offsets.tolist()\n",
    "    col_offsets = col_offsets.tolist()\n",
    "    \n",
    "    offsets = product(col_offsets, row_offsets)\n",
    "    \n",
    "    indices = product(range(len(col_offsets)), range(len(row_offsets)))\n",
    "    \n",
    "    big_window = rio_windows.Window(col_off=0, row_off=0, width=img_width, height=img_height)\n",
    "    \n",
    "    for index, (col_off, row_off) in zip(indices, offsets):\n",
    "        window = rio_windows.Window(\n",
    "            col_off=col_off,\n",
    "            row_off=row_off,\n",
    "            width=win_width,\n",
    "            height=win_height\n",
    "        )\n",
    "        if boundless:\n",
    "            yield index, window\n",
    "        else:\n",
    "            yield index, window.intersection(big_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterDataGenerator(Sequence):\n",
    "    def __init__(\n",
    "        self,  \n",
    "        map_dict,\n",
    "        channels,\n",
    "        img_height,\n",
    "        img_width,\n",
    "        win_height,\n",
    "        win_width,\n",
    "        min_hoverlap,\n",
    "        min_woverlap,\n",
    "        cls_count,\n",
    "        augs=None, # list of tuples like (fn, flag), fn: aug function works on channel first image, flag: wheather fn should be applied on labels\n",
    "        boundless=False,\n",
    "        shuffle=True,\n",
    "        batch_size=1,\n",
    "    ):\n",
    "        assert isinstance(map_dict, dict), 'Invalid type for parameter <map_dict>, expected type `dict`!'\n",
    "        assert all([set(map_dict[k].keys()) == {'IMAGE', 'LABEL'} for k in map_dict.keys()]), \"Invalid map <dict_map>, Key Mismatch!\"\n",
    "        if augs is None:\n",
    "            augs = (((lambda m : m), True),)\n",
    "        else:\n",
    "            assert isinstance(augs, (tuple, list)) and all(\n",
    "                [callable(fn) and isinstance(flag, bool) for (fn, flag) in augs]\n",
    "            )\n",
    "        \n",
    "        couples =  [(Path(couple['IMAGE']).as_posix(), Path(couple['LABEL']).as_posix()) for couple in map_dict.values()]\n",
    "        \n",
    "        windows = list(\n",
    "            generate_windows(\n",
    "                img_height=img_height,\n",
    "                img_width=img_width,\n",
    "                win_height=win_height,\n",
    "                win_width=win_width,\n",
    "                min_hoverlap=min_hoverlap,\n",
    "                min_woverlap=min_woverlap,\n",
    "                boundless=boundless\n",
    "            )\n",
    "        )\n",
    "        dat = list(product(couples, windows, augs))\n",
    "        if shuffle:\n",
    "            random.shuffle(dat)\n",
    "        self.data = dat\n",
    "        self.channels = channels\n",
    "        self.class_count = cls_count\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_batch = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        islices = list()\n",
    "        lslices = list()\n",
    "        for (im, lb), (_, w), (aug, af) in current_batch:\n",
    "            with rio.open(im, 'r') as isrc:\n",
    "                islice = isrc.read(indexes=self.channels, window=w, boundless=boundless_flag, masked=False)\n",
    "                islice = aug(islice)\n",
    "                islice = np.moveaxis(a=islice, source=0, destination=-1)\n",
    "                islices.append(islice)\n",
    "            with rio.open(lb, 'r') as lsrc:\n",
    "                lslice = lsrc.read(window=w, boundless=boundless_flag, masked=False)\n",
    "                if af is True:\n",
    "                    lslice = aug(lslice)\n",
    "                lslice = np.moveaxis(a=lslice, source=0, destination=-1)\n",
    "                lslice =to_categorical(\n",
    "                    y=(lslice-1), \n",
    "                    num_classes=self.class_count\n",
    "                )\n",
    "                lslices.append(lslice)\n",
    "        ibatch = np.stack(islices, axis=0)\n",
    "        lbatch = np.stack(lslices, axis=0)\n",
    "        return ibatch, lbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(input_shape, f=128):\n",
    "    input_layer = Input(shape=(None, None, image_features))\n",
    "    \n",
    "    c1 = Conv2D(\n",
    "        filters=128, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(input_layer)\n",
    "    c2 = Conv2D(\n",
    "        filters=128, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(c1)\n",
    "    return input_layer, c2\n",
    "\n",
    "def res_block(p_layer, f=128):\n",
    "    l1 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        dilation_rate=2,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(p_layer)\n",
    "    l1 = BatchNormalization()(l1)\n",
    "    l2 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        dilation_rate=2,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(l1)\n",
    "    l2 = BatchNormalization()(l2)\n",
    "    l3 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        dilation_rate=2,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(l2)\n",
    "    l3 = BatchNormalization()(l3)\n",
    "    \n",
    "    a = Add()([p_layer, l3])\n",
    "    res = Activation('relu')(a)\n",
    "    return res\n",
    "    \n",
    "def branch_block(parent_layer, f=128):\n",
    "    m1 = MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "    )(parent_layer)\n",
    "    c3 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        activation='relu',\n",
    "        padding='same', \n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(m1)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c4 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        activation='relu',\n",
    "        padding='same', \n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(c3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    return c4\n",
    "\n",
    "def downsample(p_layer, f=128, scale=2):\n",
    "    cd1 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        strides=scale,\n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(p_layer)\n",
    "    cd1 = BatchNormalization()(cd1)\n",
    "    c5 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(cd1)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c6 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(c5)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    return c6\n",
    "\n",
    "def stack_block(main_layer, parent_layer, f=128, scale=2):\n",
    "    b1 = branch_block(parent_layer=parent_layer, f=f)\n",
    "    b2 = downsample(p_layer=main_layer, f=f, scale=scale)\n",
    "    a1 = Add()([b1, b2])\n",
    "    res_b = res_block(p_layer=a1, f=f)\n",
    "    return res_b\n",
    "\n",
    "def stack_mid(parent):\n",
    "    f = int_shape(parent)[-1]\n",
    "    r1 = res_block(p_layer=parent, f=f)\n",
    "    r2 = res_block(p_layer=r1, f=f)\n",
    "    r3 = res_block(p_layer=r2, f=f)\n",
    "    \n",
    "    d1 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        dilation_rate=1,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(r3)\n",
    "    d1 = BatchNormalization()(d1)\n",
    "    d2 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        dilation_rate=2,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(r3)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d3 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        dilation_rate=4,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(r3)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    d4 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        dilation_rate=8,\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(r3)\n",
    "    d4 = BatchNormalization()(d4)\n",
    "    \n",
    "    c = Concatenate(axis=-1)([d1, d2, d3, d4])\n",
    "    return c\n",
    "\n",
    "def up_merge(xx_lyr, yy_lyr, f=128):\n",
    "    c11 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(xx_lyr)\n",
    "    c11 = BatchNormalization()(c11)\n",
    "\n",
    "    c12 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(c11)\n",
    "    c12 = BatchNormalization()(c12)\n",
    "    \n",
    "    upl = UpSampling2D(size=2, interpolation='bilinear')(c12)\n",
    "    \n",
    "    cat = Concatenate(axis=-1)([upl, yy_lyr])\n",
    "    return cat\n",
    "\n",
    "def final_blk(xx_lyr, f=128, count=4):\n",
    "    c11 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(xx_lyr)\n",
    "    c11 = BatchNormalization()(c11)\n",
    "\n",
    "    c12 = Conv2D(\n",
    "        filters=f, \n",
    "        kernel_size=(3, 3), \n",
    "        padding='same', \n",
    "        activation='relu',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(c11)\n",
    "    c12 = BatchNormalization()(c12)\n",
    "    \n",
    "    cx = Conv2D(\n",
    "        filters=count, \n",
    "        kernel_size=(1, 1), \n",
    "        padding='same', \n",
    "        activation='softmax',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "    )(c11)\n",
    "    return cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = make_features(input_shape=(512, 512, image_features), f=64)\n",
    "lyr1 = stack_block(main_layer=xx, parent_layer=yy, f=128, scale=2)\n",
    "lyr2 = stack_block(main_layer=xx, parent_layer=lyr1, f=256, scale=4)\n",
    "lyr3 = stack_block(main_layer=xx, parent_layer=lyr2, f=512, scale=8)\n",
    "mid = stack_mid(parent=lyr3)\n",
    "lyr4 = up_merge(xx_lyr=mid, yy_lyr=lyr2, f=512)\n",
    "lyr5 = up_merge(xx_lyr=lyr4, yy_lyr=lyr1, f=256)\n",
    "lyr6 = up_merge(xx_lyr=lyr5, yy_lyr=yy, f=128)\n",
    "zz = final_blk(xx_lyr=lyr6, f=64, count=class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 5 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 5888        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 147584      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 5888        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 147584      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 147584      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 147584      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 1 147584      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 1 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 1 0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 1 147584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 1 512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 1 147584      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 1 147584      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 1 512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 1 0           add_1[0][0]                      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 1 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 2 11776       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 2 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 2 590080      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 2 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 590080      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 2 590080      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 2 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 2 590080      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 2 590080      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 2 1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 2 590080      batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 2 0           add_3[0][0]                      \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 2 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 5 23552       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 5 2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 5 1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 5 2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 5 2048        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 5 2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 5 2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 5 2359808     add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 5 2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 5 2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 5 2048        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           add_5[0][0]                      \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 5 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 5 2359808     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 5 2048        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 5 2359808     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 5 2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 5 2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 5 0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 5 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 5 2359808     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 5 2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 5 0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 5 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 5 2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 5 2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 5 2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 5 2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 5 2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 5 2048        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
      "                                                                 batch_normalization_35[0][0]     \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 5 9437696     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 5 2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 5 2359808     batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 2 1769728     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 2 590080      batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 2 1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 2 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 442496      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 147584      batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 2 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 6 147520      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 6 256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 6 390         batch_normalization_44[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 66,037,958\n",
      "Trainable params: 66,006,598\n",
      "Non-trainable params: 31,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xnet_classifier = Model(inputs=xx, outputs=zz)\n",
    "xnet_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# xnet_classifier = xnet(\n",
    "#     input_shape=(None, None, image_features),\n",
    "#     num_classes=class_count,\n",
    "#     activation=\"relu\",\n",
    "#     use_batch_norm=True,\n",
    "#     upsample_mode=\"deconv\",  # 'deconv' or 'simple'\n",
    "#     dropout=droprate,\n",
    "#     dropout_change_per_layer=0.0,\n",
    "#     dropout_type=\"standard\",\n",
    "#     use_dropout_on_upsampling=False,\n",
    "#     use_attention=True,\n",
    "#     filters=64,\n",
    "#     num_layers=4,\n",
    "#     output_activation=\"softmax\",\n",
    "# )\n",
    "# xnet_classifier.summary(line_length=116)\n",
    "# plot_model(xnet_classifier, to_file=mplot, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_val_loss = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n",
    "# es_val_accu = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001)\n",
    "mc_val_accu = ModelCheckpoint(str(model_max_accuracy.absolute()), monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "mc_val_loss = ModelCheckpoint(str(model_min_loss.absolute()), monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "tb = TensorBoard(\n",
    "    log_dir=log_d, \n",
    "    histogram_freq=1, \n",
    "    write_graph=True, \n",
    "    write_images=True,\n",
    "    update_freq='batch', \n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")\n",
    "\n",
    "# Load Pre Trained Weights if any\n",
    "# if model_max_accuracy.is_file():\n",
    "#     xnet_classifier.load_weights(str(model_max_accuracy))\n",
    "\n",
    "xnet_classifier.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4), \n",
    "    # loss='categorical_crossentropy', \n",
    "    loss=focal_tversky_loss(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = RasterDataGenerator( \n",
    "    map_dict=train_map,\n",
    "    channels=bands,\n",
    "    img_height=image_height,\n",
    "    img_width=image_width,\n",
    "    win_height=window_height,\n",
    "    win_width=window_width,\n",
    "    min_hoverlap=min_height_overlap,\n",
    "    min_woverlap=min_width_overlap,\n",
    "    cls_count=class_count,\n",
    "    boundless=boundless_flag,\n",
    "    # augs=geo_augs,\n",
    "    augs=None,\n",
    "    shuffle=data_shuffle,\n",
    "    batch_size=batchsize\n",
    ")\n",
    "valid_generator = RasterDataGenerator(\n",
    "    map_dict=valid_map,\n",
    "    channels=bands,\n",
    "    img_height=image_height,\n",
    "    img_width=image_width,\n",
    "    win_height=window_height,\n",
    "    win_width=window_width,\n",
    "    min_hoverlap=1,\n",
    "    min_woverlap=1,\n",
    "    cls_count=class_count,\n",
    "    augs=None,\n",
    "    boundless=boundless_flag,\n",
    "    shuffle=data_shuffle,\n",
    "    batch_size=batchsize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3211/3211 [==============================] - 2111s 658ms/step - loss: 0.6210 - accuracy: 0.6914 - val_loss: 0.8237 - val_accuracy: 0.7433\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82369, saving model to D:\\UNet\\Models\\Model_MinLoss.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74333, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 2/50\n",
      "3211/3211 [==============================] - 2102s 655ms/step - loss: 0.5673 - accuracy: 0.7480 - val_loss: 0.8915 - val_accuracy: 0.7572\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.82369\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74333 to 0.75719, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 3/50\n",
      "3211/3211 [==============================] - 2099s 654ms/step - loss: 0.5485 - accuracy: 0.7676 - val_loss: 0.9109 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.82369\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75719 to 0.76395, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 4/50\n",
      "3211/3211 [==============================] - 2100s 654ms/step - loss: 0.5353 - accuracy: 0.7811 - val_loss: 0.7886 - val_accuracy: 0.8016\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.82369 to 0.78862, saving model to D:\\UNet\\Models\\Model_MinLoss.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.76395 to 0.80164, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 5/50\n",
      "3211/3211 [==============================] - 2105s 656ms/step - loss: 0.5256 - accuracy: 0.7917 - val_loss: 0.7931 - val_accuracy: 0.8355\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.78862\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80164 to 0.83545, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 6/50\n",
      "3211/3211 [==============================] - 2109s 657ms/step - loss: 0.5172 - accuracy: 0.8002 - val_loss: 0.8522 - val_accuracy: 0.8217\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.78862\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.83545\n",
      "Epoch 7/50\n",
      "3211/3211 [==============================] - 2098s 654ms/step - loss: 0.5099 - accuracy: 0.8080 - val_loss: 0.7748 - val_accuracy: 0.8338\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.78862 to 0.77475, saving model to D:\\UNet\\Models\\Model_MinLoss.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.83545\n",
      "Epoch 8/50\n",
      "3211/3211 [==============================] - 2100s 654ms/step - loss: 0.5040 - accuracy: 0.8141 - val_loss: 0.7769 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.77475\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83545\n",
      "Epoch 9/50\n",
      "3211/3211 [==============================] - 2103s 655ms/step - loss: 0.5000 - accuracy: 0.8183 - val_loss: 0.7886 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.77475\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83545\n",
      "Epoch 10/50\n",
      "3211/3211 [==============================] - 2101s 654ms/step - loss: 0.4948 - accuracy: 0.8237 - val_loss: 0.7916 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.77475\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.83545 to 0.84263, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 11/50\n",
      "3211/3211 [==============================] - 2107s 656ms/step - loss: 0.4910 - accuracy: 0.8276 - val_loss: 0.7718 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.77475 to 0.77183, saving model to D:\\UNet\\Models\\Model_MinLoss.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.84263 to 0.85754, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 12/50\n",
      "3211/3211 [==============================] - 2109s 657ms/step - loss: 0.4845 - accuracy: 0.8339 - val_loss: 0.9079 - val_accuracy: 0.7695\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.77183\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.85754\n",
      "Epoch 13/50\n",
      "3211/3211 [==============================] - 2124s 662ms/step - loss: 0.4824 - accuracy: 0.8344 - val_loss: 0.7786 - val_accuracy: 0.7827\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.77183\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.85754\n",
      "Epoch 14/50\n",
      "3211/3211 [==============================] - 2183s 680ms/step - loss: 0.4796 - accuracy: 0.8373 - val_loss: 0.8669 - val_accuracy: 0.8335\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.77183\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.85754\n",
      "Epoch 15/50\n",
      "3211/3211 [==============================] - 2165s 674ms/step - loss: 0.4721 - accuracy: 0.8444 - val_loss: 0.7751 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.77183\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.85754 to 0.86235, saving model to D:\\UNet\\Models\\Model_MaxAccuracy.h5\n",
      "Epoch 16/50\n",
      "3211/3211 [==============================] - 2143s 668ms/step - loss: 0.4704 - accuracy: 0.8459 - val_loss: 0.7922 - val_accuracy: 0.8317\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.77183\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.86235\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20f02dad548>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "xnet_classifier.fit_generator(\n",
    "    generator=train_generator, \n",
    "    epochs=50, \n",
    "    validation_data=valid_generator,\n",
    "    use_multiprocessing=False,\n",
    "    callbacks=[\n",
    "        tb,\n",
    "        es_val_loss,\n",
    "        mc_val_loss,\n",
    "#         es_val_accu,\n",
    "        mc_val_accu,\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
